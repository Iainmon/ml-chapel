{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import emnist\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import loader\n",
    "mnist_images, mnist_labels = emnist.extract_test_samples('digits')\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "# animals_dataset = loader.load_chapel_dataset('./animals-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1,out_channels=12,kernel_size=3,stride=2),\n",
    "    nn.Conv2d(in_channels=12,out_channels=16,kernel_size=4,stride=1),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.LazyLinear(out_features=10),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 12, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (1): Conv2d(12, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  (4): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = mnist_images[0,:,:]\n",
    "img = torch.from_numpy(img.reshape(1,1,28,28)).float()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2066e-12, 9.9853e-01, 3.2197e-38, 9.9211e-33, 2.8813e-23, 5.7358e-26,\n",
       "         1.4662e-03, 9.5889e-17, 4.2346e-19, 7.2227e-24]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img).shape\n",
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/var/folders/wt/nr12w9r958d0nwkk86zwr9600000gp/T/ipykernel_6168/1003746249.py:27: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm(total=num_batches) as pbar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d6b5fb6f7c4e79a4b37ea3afe2dd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.056213363083203634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f678b80cf7be4f11b7c7d64aadb6487d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.05052134224971135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f468c57567347069efd0e280b73214f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.05006765194336573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa278b5e635499fa7e4f1a8ee91a89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.04985096321900686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a750d98f7d0840999175b729b6ab1cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.049726322877407074\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1,out_channels=12,kernel_size=3,stride=2),\n",
    "    nn.Conv2d(in_channels=12,out_channels=16,kernel_size=4,stride=1),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.LazyLinear(out_features=10),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "learning_rate = 0.05\n",
    "batch_size = 30\n",
    "\n",
    "loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    num_pairs = len(train_dataset)# mnist_images.shape[0]\n",
    "    num_batches = num_pairs // batch_size\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for batch, labels in train_loader:\n",
    "            # for b in range(num_batches):\n",
    "            # batch = mnist_images[b*batch_size:(b+1)*batch_size,:,:]\n",
    "            # batch = torch.from_numpy(batch.reshape(batch_size,1,28,28)).float() / 255\n",
    "            # labels = torch.from_numpy(mnist_labels[b*batch_size:(b+1)*batch_size])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = loss_criterion(output,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "            # print(loss.item())\n",
    "        # for (im_idx, label) in zip(range(num_pairs), mnist_labels):\n",
    "        #     im = mnist_images[im_idx,:,:]\n",
    "        #     im = torch.from_numpy(im.reshape(1,1,28,28)).float()\n",
    "\n",
    "        #     optimizer.zero_grad()\n",
    "        #     output = model(im)\n",
    "        #     label_vector = torch.zeros(1,10)\n",
    "        #     label_vector[0,label] = 1\n",
    "        #     loss = loss_fn(output,label_vector)# -torch.sum(torch.log(output))\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "        #     # print(loss.item(),output[0,label].item())\n",
    "        #     epoch_loss += loss.item() \n",
    "        #     pbar.update(1)\n",
    "    print('loss: ', epoch_loss / num_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  9723 / 10000\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "for data,target in test_loader:\n",
    "    output = model(data)\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "print('accuracy: ', correct ,'/', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(im,lb) = next(iter(train_loader))\n",
    "lb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToTensor()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
