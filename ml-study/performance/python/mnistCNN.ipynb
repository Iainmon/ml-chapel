{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import emnist\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import loader\n",
    "mnist_images, mnist_labels = emnist.extract_test_samples('digits')\n",
    "# animals_dataset = loader.load_chapel_dataset('./animals-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1,out_channels=12,kernel_size=3,stride=2),\n",
    "    nn.Conv2d(in_channels=12,out_channels=16,kernel_size=4,stride=1),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.LazyLinear(out_features=10),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 12, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (1): Conv2d(12, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  (4): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = mnist_images[0,:,:]\n",
    "img = torch.from_numpy(img.reshape(1,1,28,28)).float()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2066e-12, 9.9853e-01, 3.2197e-38, 9.9211e-33, 2.8813e-23, 5.7358e-26,\n",
       "         1.4662e-03, 9.5889e-17, 4.2346e-19, 7.2227e-24]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img).shape\n",
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/nr12w9r958d0nwkk86zwr9600000gp/T/ipykernel_6168/4022610662.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm(total=num_pairs) as pbar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019a674ca78448ec8c502c63ee0a4f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.3612710447967054\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1,out_channels=12,kernel_size=3,stride=2),\n",
    "    nn.Conv2d(in_channels=12,out_channels=16,kernel_size=4,stride=1),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.LazyLinear(out_features=10),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "epochs = 1\n",
    "learning_rate = 0.005\n",
    "batch_size = 10\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    num_pairs = mnist_images.shape[0]\n",
    "    num_batches = num_pairs / batch_size\n",
    "    with tqdm(total=num_pairs) as pbar:\n",
    "        for (im_idx, label) in zip(range(num_pairs), mnist_labels):\n",
    "            im = mnist_images[im_idx,:,:]\n",
    "            im = torch.from_numpy(im.reshape(1,1,28,28)).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(im)\n",
    "            label_vector = torch.zeros(1,10)\n",
    "            label_vector[0,label] = 1\n",
    "            loss = loss_fn(output,label_vector)# -torch.sum(torch.log(output))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(loss.item(),output[0,label].item())\n",
    "            epoch_loss += loss.item() \n",
    "            pbar.update(1)\n",
    "    print('loss: ', epoch_loss / num_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
